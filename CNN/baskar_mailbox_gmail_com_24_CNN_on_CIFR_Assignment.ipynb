{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "baskar.mailbox@gmail.com_24_CNN_on_CIFR_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kK3alCdFflQX"
      },
      "source": [
        "### CNN on CIFR Assignment:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cHCYMwwXflQd"
      },
      "source": [
        "1.  Please visit this link to access the state-of-art DenseNet code for reference - DenseNet - cifar10 notebook link\n",
        "2.  You need to create a copy of this and \"retrain\" this model to achieve 90+ test accuracy. \n",
        "3.  You cannot use Dense Layers (also called fully connected layers), or DropOut.\n",
        "4.  You MUST use Image Augmentation Techniques.\n",
        "5.  You cannot use an already trained model as a beginning points, you have to initilize as your own\n",
        "6.  You cannot run the program for more than 300 Epochs, and it should be clear from your log, that you have only used 300 Epochs\n",
        "7.  You cannot use test images for training the model.\n",
        "8.  You cannot change the general architecture of DenseNet (which means you must use Dense Block, Transition and Output blocks as mentioned in the code)\n",
        "9.  You are free to change Convolution types (e.g. from 3x3 normal convolution to Depthwise Separable, etc)\n",
        "10. You cannot have more than 1 Million parameters in total\n",
        "11. You are free to move the code from Keras to Tensorflow, Pytorch, MXNET etc. \n",
        "12. You can use any optimization algorithm you need. \n",
        "13. You can checkpoint your model and retrain the model from that checkpoint so that no need of training the model from first if you lost at any epoch while training. You can directly load that model and Train from that epoch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TLVcyNYKflQi",
        "outputId": "74ba8141-19cd-4b2e-90f8-d9db431bf8a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "path = os.path.abspath('gdrive/My Drive/CNN_CIFAR')\n",
        "path = os.path.join(path, 'Cifar_training')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wVIx_KIigxPV",
        "outputId": "b28a9332-7c64-47ce-efbb-06c67fd3b3f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.optimizers import Adam, RMSprop, SGD\n",
        "from keras import regularizers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tTa92aq3YCwF",
        "colab": {}
      },
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "num_filter = 32\n",
        "compression = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mB7o3zu1g6eT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ba613583-5ee4-4b4c-c95e-bd93ac7a3a53"
      },
      "source": [
        "# Load CIFAR10 Data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ee-sge5Kg7vr",
        "colab": {}
      },
      "source": [
        "# Dense Block\n",
        "def denseblock(input, num_filter = 32):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l): \n",
        "        BatchNorm = layers.BatchNormalization()(temp)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        temp = concat\n",
        "    return temp\n",
        "\n",
        "## transition Blosck\n",
        "def transition(input, num_filter = 32):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    return avg\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "anPCpQWhhGb7",
        "colab": {}
      },
      "source": [
        "num_filter = 32\n",
        "l = 12\n",
        "input = layers.Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = denseblock(First_Conv2D, num_filter)\n",
        "First_Transition = transition(First_Block, num_filter)\n",
        "\n",
        "Second_Block = denseblock(First_Transition, num_filter)\n",
        "Second_Transition = transition(Second_Block, num_filter)\n",
        "\n",
        "Third_Block = denseblock(Second_Transition, num_filter)\n",
        "Third_Transition = transition(Third_Block, num_filter)\n",
        "\n",
        "Last_Block = denseblock(Third_Transition,  num_filter)\n",
        "\n",
        "BatchNorm = layers.BatchNormalization()(Last_Block)\n",
        "relu = layers.Activation('relu')(BatchNorm)\n",
        "AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
        "conv_output=layers.Conv2D(10,(2,2))(AvgPooling)\n",
        "conv_output1=layers.Conv2D(10,(1,1))(conv_output)\n",
        "output=layers.Flatten()(conv_output1)\n",
        "output = layers.Activation('softmax')(output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GirCS8reYwS3",
        "outputId": "e5bfd092-86b0-4ce1-b155-ee5276c18a35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_743 (Conv2D)             (None, 32, 32, 32)   864         input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_728 (BatchN (None, 32, 32, 32)   128         conv2d_743[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_745 (Activation)     (None, 32, 32, 32)   0           batch_normalization_728[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_744 (Conv2D)             (None, 32, 32, 16)   4608        activation_745[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_672 (Concatenate)   (None, 32, 32, 48)   0           conv2d_743[0][0]                 \n",
            "                                                                 conv2d_744[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_729 (BatchN (None, 32, 32, 48)   192         concatenate_672[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_746 (Activation)     (None, 32, 32, 48)   0           batch_normalization_729[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_745 (Conv2D)             (None, 32, 32, 16)   6912        activation_746[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_673 (Concatenate)   (None, 32, 32, 64)   0           concatenate_672[0][0]            \n",
            "                                                                 conv2d_745[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_730 (BatchN (None, 32, 32, 64)   256         concatenate_673[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_747 (Activation)     (None, 32, 32, 64)   0           batch_normalization_730[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_746 (Conv2D)             (None, 32, 32, 16)   9216        activation_747[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_674 (Concatenate)   (None, 32, 32, 80)   0           concatenate_673[0][0]            \n",
            "                                                                 conv2d_746[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_731 (BatchN (None, 32, 32, 80)   320         concatenate_674[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_748 (Activation)     (None, 32, 32, 80)   0           batch_normalization_731[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_747 (Conv2D)             (None, 32, 32, 16)   11520       activation_748[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_675 (Concatenate)   (None, 32, 32, 96)   0           concatenate_674[0][0]            \n",
            "                                                                 conv2d_747[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_732 (BatchN (None, 32, 32, 96)   384         concatenate_675[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_749 (Activation)     (None, 32, 32, 96)   0           batch_normalization_732[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_748 (Conv2D)             (None, 32, 32, 16)   13824       activation_749[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_676 (Concatenate)   (None, 32, 32, 112)  0           concatenate_675[0][0]            \n",
            "                                                                 conv2d_748[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_733 (BatchN (None, 32, 32, 112)  448         concatenate_676[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_750 (Activation)     (None, 32, 32, 112)  0           batch_normalization_733[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_749 (Conv2D)             (None, 32, 32, 16)   16128       activation_750[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_677 (Concatenate)   (None, 32, 32, 128)  0           concatenate_676[0][0]            \n",
            "                                                                 conv2d_749[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_734 (BatchN (None, 32, 32, 128)  512         concatenate_677[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_751 (Activation)     (None, 32, 32, 128)  0           batch_normalization_734[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_750 (Conv2D)             (None, 32, 32, 16)   18432       activation_751[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_678 (Concatenate)   (None, 32, 32, 144)  0           concatenate_677[0][0]            \n",
            "                                                                 conv2d_750[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_735 (BatchN (None, 32, 32, 144)  576         concatenate_678[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_752 (Activation)     (None, 32, 32, 144)  0           batch_normalization_735[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_751 (Conv2D)             (None, 32, 32, 16)   20736       activation_752[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_679 (Concatenate)   (None, 32, 32, 160)  0           concatenate_678[0][0]            \n",
            "                                                                 conv2d_751[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_736 (BatchN (None, 32, 32, 160)  640         concatenate_679[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_753 (Activation)     (None, 32, 32, 160)  0           batch_normalization_736[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_752 (Conv2D)             (None, 32, 32, 16)   23040       activation_753[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_680 (Concatenate)   (None, 32, 32, 176)  0           concatenate_679[0][0]            \n",
            "                                                                 conv2d_752[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_737 (BatchN (None, 32, 32, 176)  704         concatenate_680[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_754 (Activation)     (None, 32, 32, 176)  0           batch_normalization_737[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_753 (Conv2D)             (None, 32, 32, 16)   25344       activation_754[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_681 (Concatenate)   (None, 32, 32, 192)  0           concatenate_680[0][0]            \n",
            "                                                                 conv2d_753[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_738 (BatchN (None, 32, 32, 192)  768         concatenate_681[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_755 (Activation)     (None, 32, 32, 192)  0           batch_normalization_738[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_754 (Conv2D)             (None, 32, 32, 16)   27648       activation_755[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_682 (Concatenate)   (None, 32, 32, 208)  0           concatenate_681[0][0]            \n",
            "                                                                 conv2d_754[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_739 (BatchN (None, 32, 32, 208)  832         concatenate_682[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_756 (Activation)     (None, 32, 32, 208)  0           batch_normalization_739[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_755 (Conv2D)             (None, 32, 32, 16)   29952       activation_756[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_683 (Concatenate)   (None, 32, 32, 224)  0           concatenate_682[0][0]            \n",
            "                                                                 conv2d_755[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_740 (BatchN (None, 32, 32, 224)  896         concatenate_683[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_757 (Activation)     (None, 32, 32, 224)  0           batch_normalization_740[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_756 (Conv2D)             (None, 32, 32, 16)   3584        activation_757[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_56 (AveragePo (None, 16, 16, 16)   0           conv2d_756[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_741 (BatchN (None, 16, 16, 16)   64          average_pooling2d_56[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_758 (Activation)     (None, 16, 16, 16)   0           batch_normalization_741[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_757 (Conv2D)             (None, 16, 16, 16)   2304        activation_758[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_684 (Concatenate)   (None, 16, 16, 32)   0           average_pooling2d_56[0][0]       \n",
            "                                                                 conv2d_757[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_742 (BatchN (None, 16, 16, 32)   128         concatenate_684[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_759 (Activation)     (None, 16, 16, 32)   0           batch_normalization_742[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_758 (Conv2D)             (None, 16, 16, 16)   4608        activation_759[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_685 (Concatenate)   (None, 16, 16, 48)   0           concatenate_684[0][0]            \n",
            "                                                                 conv2d_758[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_743 (BatchN (None, 16, 16, 48)   192         concatenate_685[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_760 (Activation)     (None, 16, 16, 48)   0           batch_normalization_743[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_759 (Conv2D)             (None, 16, 16, 16)   6912        activation_760[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_686 (Concatenate)   (None, 16, 16, 64)   0           concatenate_685[0][0]            \n",
            "                                                                 conv2d_759[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_744 (BatchN (None, 16, 16, 64)   256         concatenate_686[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_761 (Activation)     (None, 16, 16, 64)   0           batch_normalization_744[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_760 (Conv2D)             (None, 16, 16, 16)   9216        activation_761[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_687 (Concatenate)   (None, 16, 16, 80)   0           concatenate_686[0][0]            \n",
            "                                                                 conv2d_760[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_745 (BatchN (None, 16, 16, 80)   320         concatenate_687[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_762 (Activation)     (None, 16, 16, 80)   0           batch_normalization_745[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_761 (Conv2D)             (None, 16, 16, 16)   11520       activation_762[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_688 (Concatenate)   (None, 16, 16, 96)   0           concatenate_687[0][0]            \n",
            "                                                                 conv2d_761[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_746 (BatchN (None, 16, 16, 96)   384         concatenate_688[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_763 (Activation)     (None, 16, 16, 96)   0           batch_normalization_746[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_762 (Conv2D)             (None, 16, 16, 16)   13824       activation_763[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_689 (Concatenate)   (None, 16, 16, 112)  0           concatenate_688[0][0]            \n",
            "                                                                 conv2d_762[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_747 (BatchN (None, 16, 16, 112)  448         concatenate_689[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_764 (Activation)     (None, 16, 16, 112)  0           batch_normalization_747[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_763 (Conv2D)             (None, 16, 16, 16)   16128       activation_764[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_690 (Concatenate)   (None, 16, 16, 128)  0           concatenate_689[0][0]            \n",
            "                                                                 conv2d_763[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_748 (BatchN (None, 16, 16, 128)  512         concatenate_690[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_765 (Activation)     (None, 16, 16, 128)  0           batch_normalization_748[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_764 (Conv2D)             (None, 16, 16, 16)   18432       activation_765[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_691 (Concatenate)   (None, 16, 16, 144)  0           concatenate_690[0][0]            \n",
            "                                                                 conv2d_764[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_749 (BatchN (None, 16, 16, 144)  576         concatenate_691[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_766 (Activation)     (None, 16, 16, 144)  0           batch_normalization_749[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_765 (Conv2D)             (None, 16, 16, 16)   20736       activation_766[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_692 (Concatenate)   (None, 16, 16, 160)  0           concatenate_691[0][0]            \n",
            "                                                                 conv2d_765[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_750 (BatchN (None, 16, 16, 160)  640         concatenate_692[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_767 (Activation)     (None, 16, 16, 160)  0           batch_normalization_750[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_766 (Conv2D)             (None, 16, 16, 16)   23040       activation_767[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_693 (Concatenate)   (None, 16, 16, 176)  0           concatenate_692[0][0]            \n",
            "                                                                 conv2d_766[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_751 (BatchN (None, 16, 16, 176)  704         concatenate_693[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_768 (Activation)     (None, 16, 16, 176)  0           batch_normalization_751[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_767 (Conv2D)             (None, 16, 16, 16)   25344       activation_768[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_694 (Concatenate)   (None, 16, 16, 192)  0           concatenate_693[0][0]            \n",
            "                                                                 conv2d_767[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_752 (BatchN (None, 16, 16, 192)  768         concatenate_694[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_769 (Activation)     (None, 16, 16, 192)  0           batch_normalization_752[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_768 (Conv2D)             (None, 16, 16, 16)   27648       activation_769[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_695 (Concatenate)   (None, 16, 16, 208)  0           concatenate_694[0][0]            \n",
            "                                                                 conv2d_768[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_753 (BatchN (None, 16, 16, 208)  832         concatenate_695[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_770 (Activation)     (None, 16, 16, 208)  0           batch_normalization_753[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_769 (Conv2D)             (None, 16, 16, 16)   3328        activation_770[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_57 (AveragePo (None, 8, 8, 16)     0           conv2d_769[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_754 (BatchN (None, 8, 8, 16)     64          average_pooling2d_57[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_771 (Activation)     (None, 8, 8, 16)     0           batch_normalization_754[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_770 (Conv2D)             (None, 8, 8, 16)     2304        activation_771[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_696 (Concatenate)   (None, 8, 8, 32)     0           average_pooling2d_57[0][0]       \n",
            "                                                                 conv2d_770[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_755 (BatchN (None, 8, 8, 32)     128         concatenate_696[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_772 (Activation)     (None, 8, 8, 32)     0           batch_normalization_755[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_771 (Conv2D)             (None, 8, 8, 16)     4608        activation_772[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_697 (Concatenate)   (None, 8, 8, 48)     0           concatenate_696[0][0]            \n",
            "                                                                 conv2d_771[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_756 (BatchN (None, 8, 8, 48)     192         concatenate_697[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_773 (Activation)     (None, 8, 8, 48)     0           batch_normalization_756[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_772 (Conv2D)             (None, 8, 8, 16)     6912        activation_773[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_698 (Concatenate)   (None, 8, 8, 64)     0           concatenate_697[0][0]            \n",
            "                                                                 conv2d_772[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_757 (BatchN (None, 8, 8, 64)     256         concatenate_698[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_774 (Activation)     (None, 8, 8, 64)     0           batch_normalization_757[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_773 (Conv2D)             (None, 8, 8, 16)     9216        activation_774[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_699 (Concatenate)   (None, 8, 8, 80)     0           concatenate_698[0][0]            \n",
            "                                                                 conv2d_773[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_758 (BatchN (None, 8, 8, 80)     320         concatenate_699[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_775 (Activation)     (None, 8, 8, 80)     0           batch_normalization_758[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_774 (Conv2D)             (None, 8, 8, 16)     11520       activation_775[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_700 (Concatenate)   (None, 8, 8, 96)     0           concatenate_699[0][0]            \n",
            "                                                                 conv2d_774[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_759 (BatchN (None, 8, 8, 96)     384         concatenate_700[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_776 (Activation)     (None, 8, 8, 96)     0           batch_normalization_759[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_775 (Conv2D)             (None, 8, 8, 16)     13824       activation_776[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_701 (Concatenate)   (None, 8, 8, 112)    0           concatenate_700[0][0]            \n",
            "                                                                 conv2d_775[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_760 (BatchN (None, 8, 8, 112)    448         concatenate_701[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_777 (Activation)     (None, 8, 8, 112)    0           batch_normalization_760[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_776 (Conv2D)             (None, 8, 8, 16)     16128       activation_777[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_702 (Concatenate)   (None, 8, 8, 128)    0           concatenate_701[0][0]            \n",
            "                                                                 conv2d_776[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_761 (BatchN (None, 8, 8, 128)    512         concatenate_702[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_778 (Activation)     (None, 8, 8, 128)    0           batch_normalization_761[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_777 (Conv2D)             (None, 8, 8, 16)     18432       activation_778[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_703 (Concatenate)   (None, 8, 8, 144)    0           concatenate_702[0][0]            \n",
            "                                                                 conv2d_777[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_762 (BatchN (None, 8, 8, 144)    576         concatenate_703[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_779 (Activation)     (None, 8, 8, 144)    0           batch_normalization_762[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_778 (Conv2D)             (None, 8, 8, 16)     20736       activation_779[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_704 (Concatenate)   (None, 8, 8, 160)    0           concatenate_703[0][0]            \n",
            "                                                                 conv2d_778[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_763 (BatchN (None, 8, 8, 160)    640         concatenate_704[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_780 (Activation)     (None, 8, 8, 160)    0           batch_normalization_763[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_779 (Conv2D)             (None, 8, 8, 16)     23040       activation_780[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_705 (Concatenate)   (None, 8, 8, 176)    0           concatenate_704[0][0]            \n",
            "                                                                 conv2d_779[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_764 (BatchN (None, 8, 8, 176)    704         concatenate_705[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_781 (Activation)     (None, 8, 8, 176)    0           batch_normalization_764[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_780 (Conv2D)             (None, 8, 8, 16)     25344       activation_781[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_706 (Concatenate)   (None, 8, 8, 192)    0           concatenate_705[0][0]            \n",
            "                                                                 conv2d_780[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_765 (BatchN (None, 8, 8, 192)    768         concatenate_706[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_782 (Activation)     (None, 8, 8, 192)    0           batch_normalization_765[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_781 (Conv2D)             (None, 8, 8, 16)     27648       activation_782[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_707 (Concatenate)   (None, 8, 8, 208)    0           concatenate_706[0][0]            \n",
            "                                                                 conv2d_781[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_766 (BatchN (None, 8, 8, 208)    832         concatenate_707[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_783 (Activation)     (None, 8, 8, 208)    0           batch_normalization_766[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_782 (Conv2D)             (None, 8, 8, 16)     3328        activation_783[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_58 (AveragePo (None, 4, 4, 16)     0           conv2d_782[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_767 (BatchN (None, 4, 4, 16)     64          average_pooling2d_58[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_784 (Activation)     (None, 4, 4, 16)     0           batch_normalization_767[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_783 (Conv2D)             (None, 4, 4, 16)     2304        activation_784[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_708 (Concatenate)   (None, 4, 4, 32)     0           average_pooling2d_58[0][0]       \n",
            "                                                                 conv2d_783[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_768 (BatchN (None, 4, 4, 32)     128         concatenate_708[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_785 (Activation)     (None, 4, 4, 32)     0           batch_normalization_768[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_784 (Conv2D)             (None, 4, 4, 16)     4608        activation_785[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_709 (Concatenate)   (None, 4, 4, 48)     0           concatenate_708[0][0]            \n",
            "                                                                 conv2d_784[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_769 (BatchN (None, 4, 4, 48)     192         concatenate_709[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_786 (Activation)     (None, 4, 4, 48)     0           batch_normalization_769[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_785 (Conv2D)             (None, 4, 4, 16)     6912        activation_786[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_710 (Concatenate)   (None, 4, 4, 64)     0           concatenate_709[0][0]            \n",
            "                                                                 conv2d_785[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_770 (BatchN (None, 4, 4, 64)     256         concatenate_710[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_787 (Activation)     (None, 4, 4, 64)     0           batch_normalization_770[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_786 (Conv2D)             (None, 4, 4, 16)     9216        activation_787[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_711 (Concatenate)   (None, 4, 4, 80)     0           concatenate_710[0][0]            \n",
            "                                                                 conv2d_786[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_771 (BatchN (None, 4, 4, 80)     320         concatenate_711[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_788 (Activation)     (None, 4, 4, 80)     0           batch_normalization_771[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_787 (Conv2D)             (None, 4, 4, 16)     11520       activation_788[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_712 (Concatenate)   (None, 4, 4, 96)     0           concatenate_711[0][0]            \n",
            "                                                                 conv2d_787[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_772 (BatchN (None, 4, 4, 96)     384         concatenate_712[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_789 (Activation)     (None, 4, 4, 96)     0           batch_normalization_772[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_788 (Conv2D)             (None, 4, 4, 16)     13824       activation_789[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_713 (Concatenate)   (None, 4, 4, 112)    0           concatenate_712[0][0]            \n",
            "                                                                 conv2d_788[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_773 (BatchN (None, 4, 4, 112)    448         concatenate_713[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_790 (Activation)     (None, 4, 4, 112)    0           batch_normalization_773[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_789 (Conv2D)             (None, 4, 4, 16)     16128       activation_790[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_714 (Concatenate)   (None, 4, 4, 128)    0           concatenate_713[0][0]            \n",
            "                                                                 conv2d_789[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_774 (BatchN (None, 4, 4, 128)    512         concatenate_714[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_791 (Activation)     (None, 4, 4, 128)    0           batch_normalization_774[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_790 (Conv2D)             (None, 4, 4, 16)     18432       activation_791[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_715 (Concatenate)   (None, 4, 4, 144)    0           concatenate_714[0][0]            \n",
            "                                                                 conv2d_790[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_775 (BatchN (None, 4, 4, 144)    576         concatenate_715[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_792 (Activation)     (None, 4, 4, 144)    0           batch_normalization_775[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_791 (Conv2D)             (None, 4, 4, 16)     20736       activation_792[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_716 (Concatenate)   (None, 4, 4, 160)    0           concatenate_715[0][0]            \n",
            "                                                                 conv2d_791[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_776 (BatchN (None, 4, 4, 160)    640         concatenate_716[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_793 (Activation)     (None, 4, 4, 160)    0           batch_normalization_776[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_792 (Conv2D)             (None, 4, 4, 16)     23040       activation_793[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_717 (Concatenate)   (None, 4, 4, 176)    0           concatenate_716[0][0]            \n",
            "                                                                 conv2d_792[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_777 (BatchN (None, 4, 4, 176)    704         concatenate_717[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_794 (Activation)     (None, 4, 4, 176)    0           batch_normalization_777[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_793 (Conv2D)             (None, 4, 4, 16)     25344       activation_794[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_718 (Concatenate)   (None, 4, 4, 192)    0           concatenate_717[0][0]            \n",
            "                                                                 conv2d_793[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_778 (BatchN (None, 4, 4, 192)    768         concatenate_718[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_795 (Activation)     (None, 4, 4, 192)    0           batch_normalization_778[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_794 (Conv2D)             (None, 4, 4, 16)     27648       activation_795[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_719 (Concatenate)   (None, 4, 4, 208)    0           concatenate_718[0][0]            \n",
            "                                                                 conv2d_794[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_779 (BatchN (None, 4, 4, 208)    832         concatenate_719[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_796 (Activation)     (None, 4, 4, 208)    0           batch_normalization_779[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_59 (AveragePo (None, 2, 2, 208)    0           activation_796[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_795 (Conv2D)             (None, 1, 1, 10)     8330        average_pooling2d_59[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_796 (Conv2D)             (None, 1, 1, 10)     110         conv2d_795[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 10)           0           conv2d_796[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_797 (Activation)     (None, 10)           0           flatten_5[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 790,168\n",
            "Trainable params: 778,104\n",
            "Non-trainable params: 12,064\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ahWlRcS99a6",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(rotation_range = 15, horizontal_flip = True, width_shift_range = 0.1, height_shift_range = 0.1, zoom_range = 0.2, shear_range = 15)\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZS1PzI_j-OYy",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint(os.path.join(path, 'cnn_cifar_model_new1.hdf5'), monitor = 'val_acc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y0ZzXGj7-uQe",
        "colab": {}
      },
      "source": [
        "sgd=SGD(lr=0.01, momentum = 0.9)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QAZl0nsjqKa",
        "colab_type": "text"
      },
      "source": [
        "**Model: epochs:300 Test Accuracy:89%**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9S6m8C_1fLq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a71feec-25e3-41be-b20d-995887a253f5"
      },
      "source": [
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 30, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_new_30epochs.h5'))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 1.8385 - accuracy: 0.3240 - val_loss: 1.7987 - val_accuracy: 0.3746\n",
            "Epoch 2/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 1.5182 - accuracy: 0.4459 - val_loss: 1.5324 - val_accuracy: 0.4470\n",
            "Epoch 3/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 1.3841 - accuracy: 0.5002 - val_loss: 1.4850 - val_accuracy: 0.4671\n",
            "Epoch 4/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 1.2878 - accuracy: 0.5344 - val_loss: 1.5536 - val_accuracy: 0.4764\n",
            "Epoch 5/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 1.2062 - accuracy: 0.5648 - val_loss: 1.3894 - val_accuracy: 0.5274\n",
            "Epoch 6/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 1.1471 - accuracy: 0.5881 - val_loss: 1.3093 - val_accuracy: 0.5445\n",
            "Epoch 7/30\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 1.0908 - accuracy: 0.6112 - val_loss: 1.2884 - val_accuracy: 0.5687\n",
            "Epoch 8/30\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 1.0427 - accuracy: 0.6277 - val_loss: 1.1628 - val_accuracy: 0.6116\n",
            "Epoch 9/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 1.0093 - accuracy: 0.6402 - val_loss: 1.0381 - val_accuracy: 0.6353\n",
            "Epoch 10/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.9728 - accuracy: 0.6521 - val_loss: 1.0044 - val_accuracy: 0.6403\n",
            "Epoch 11/30\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 0.9431 - accuracy: 0.6624 - val_loss: 0.9891 - val_accuracy: 0.6597\n",
            "Epoch 12/30\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 0.9145 - accuracy: 0.6766 - val_loss: 0.8881 - val_accuracy: 0.6825\n",
            "Epoch 13/30\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 0.8901 - accuracy: 0.6830 - val_loss: 1.0305 - val_accuracy: 0.6368\n",
            "Epoch 14/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.8638 - accuracy: 0.6929 - val_loss: 1.0720 - val_accuracy: 0.6341\n",
            "Epoch 15/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.8421 - accuracy: 0.7008 - val_loss: 1.1271 - val_accuracy: 0.6257\n",
            "Epoch 16/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.8280 - accuracy: 0.7070 - val_loss: 0.9711 - val_accuracy: 0.6641\n",
            "Epoch 17/30\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 0.8093 - accuracy: 0.7135 - val_loss: 0.8327 - val_accuracy: 0.7083\n",
            "Epoch 18/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.7896 - accuracy: 0.7201 - val_loss: 0.8634 - val_accuracy: 0.7001\n",
            "Epoch 19/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.7752 - accuracy: 0.7266 - val_loss: 1.1867 - val_accuracy: 0.6183\n",
            "Epoch 20/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.7584 - accuracy: 0.7310 - val_loss: 0.8665 - val_accuracy: 0.7004\n",
            "Epoch 21/30\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 0.7470 - accuracy: 0.7367 - val_loss: 0.8972 - val_accuracy: 0.6973\n",
            "Epoch 22/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.7341 - accuracy: 0.7423 - val_loss: 0.7879 - val_accuracy: 0.7351\n",
            "Epoch 23/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.7194 - accuracy: 0.7439 - val_loss: 0.6973 - val_accuracy: 0.7575\n",
            "Epoch 24/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.7064 - accuracy: 0.7512 - val_loss: 0.8781 - val_accuracy: 0.7079\n",
            "Epoch 25/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.6942 - accuracy: 0.7557 - val_loss: 0.7396 - val_accuracy: 0.7510\n",
            "Epoch 26/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.6840 - accuracy: 0.7583 - val_loss: 0.8380 - val_accuracy: 0.7226\n",
            "Epoch 27/30\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 0.6720 - accuracy: 0.7635 - val_loss: 0.7876 - val_accuracy: 0.7346\n",
            "Epoch 28/30\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 0.6624 - accuracy: 0.7676 - val_loss: 0.8091 - val_accuracy: 0.7256\n",
            "Epoch 29/30\n",
            "391/390 [==============================] - 86s 221ms/step - loss: 0.6503 - accuracy: 0.7729 - val_loss: 0.6954 - val_accuracy: 0.7610\n",
            "Epoch 30/30\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 0.6408 - accuracy: 0.7759 - val_loss: 0.7821 - val_accuracy: 0.7375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2SduyeGz-2Zv",
        "outputId": "22c80b25-5d50-4e70-a0ec-526ebb7c7cf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 30, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_new_60epochs.h5'))\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.6338 - accuracy: 0.7768 - val_loss: 0.7100 - val_accuracy: 0.7604\n",
            "Epoch 2/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.6247 - accuracy: 0.7812 - val_loss: 0.7236 - val_accuracy: 0.7575\n",
            "Epoch 3/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.6162 - accuracy: 0.7827 - val_loss: 0.7967 - val_accuracy: 0.7382\n",
            "Epoch 4/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.6115 - accuracy: 0.7831 - val_loss: 0.6847 - val_accuracy: 0.7668\n",
            "Epoch 5/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.6013 - accuracy: 0.7921 - val_loss: 0.6477 - val_accuracy: 0.7801\n",
            "Epoch 6/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.5903 - accuracy: 0.7932 - val_loss: 0.7652 - val_accuracy: 0.7449\n",
            "Epoch 7/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.5824 - accuracy: 0.7960 - val_loss: 0.5867 - val_accuracy: 0.7982\n",
            "Epoch 8/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.5756 - accuracy: 0.8001 - val_loss: 0.7672 - val_accuracy: 0.7432\n",
            "Epoch 9/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.5748 - accuracy: 0.7988 - val_loss: 0.7108 - val_accuracy: 0.7669\n",
            "Epoch 10/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.5654 - accuracy: 0.8029 - val_loss: 0.6110 - val_accuracy: 0.7925\n",
            "Epoch 11/30\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 0.5587 - accuracy: 0.8038 - val_loss: 0.6078 - val_accuracy: 0.7959\n",
            "Epoch 12/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.5577 - accuracy: 0.8062 - val_loss: 0.7557 - val_accuracy: 0.7569\n",
            "Epoch 13/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.5484 - accuracy: 0.8091 - val_loss: 0.7392 - val_accuracy: 0.7635\n",
            "Epoch 14/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.5414 - accuracy: 0.8118 - val_loss: 0.7972 - val_accuracy: 0.7530\n",
            "Epoch 15/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.5350 - accuracy: 0.8126 - val_loss: 0.7559 - val_accuracy: 0.7614\n",
            "Epoch 16/30\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.5319 - accuracy: 0.8167 - val_loss: 0.6356 - val_accuracy: 0.7881\n",
            "Epoch 17/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.5250 - accuracy: 0.8160 - val_loss: 0.6528 - val_accuracy: 0.7882\n",
            "Epoch 18/30\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.5235 - accuracy: 0.8167 - val_loss: 0.7403 - val_accuracy: 0.7530\n",
            "Epoch 19/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.5103 - accuracy: 0.8228 - val_loss: 0.6608 - val_accuracy: 0.7816\n",
            "Epoch 20/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.5044 - accuracy: 0.8243 - val_loss: 0.7759 - val_accuracy: 0.7474\n",
            "Epoch 21/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.5026 - accuracy: 0.8258 - val_loss: 0.7846 - val_accuracy: 0.7537\n",
            "Epoch 22/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.4984 - accuracy: 0.8263 - val_loss: 0.6535 - val_accuracy: 0.7822\n",
            "Epoch 23/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.4932 - accuracy: 0.8277 - val_loss: 0.5989 - val_accuracy: 0.8048\n",
            "Epoch 24/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.4904 - accuracy: 0.8279 - val_loss: 0.6264 - val_accuracy: 0.8003\n",
            "Epoch 25/30\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.4853 - accuracy: 0.8305 - val_loss: 0.5826 - val_accuracy: 0.8023\n",
            "Epoch 26/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.4813 - accuracy: 0.8317 - val_loss: 0.5676 - val_accuracy: 0.8110\n",
            "Epoch 27/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.4767 - accuracy: 0.8325 - val_loss: 0.5995 - val_accuracy: 0.7962\n",
            "Epoch 28/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.4678 - accuracy: 0.8368 - val_loss: 0.6762 - val_accuracy: 0.7814\n",
            "Epoch 29/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.4664 - accuracy: 0.8376 - val_loss: 0.6559 - val_accuracy: 0.7851\n",
            "Epoch 30/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.4651 - accuracy: 0.8384 - val_loss: 0.5924 - val_accuracy: 0.8076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FnPBMukIy_Gv",
        "outputId": "6807f8de-ebec-4506-84b1-646b8c4f9262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 30, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_new_90epochs.h5'))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.4601 - accuracy: 0.8406 - val_loss: 0.5665 - val_accuracy: 0.8139\n",
            "Epoch 2/30\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.4611 - accuracy: 0.8396 - val_loss: 0.5623 - val_accuracy: 0.8140\n",
            "Epoch 3/30\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.4509 - accuracy: 0.8425 - val_loss: 0.6243 - val_accuracy: 0.7931\n",
            "Epoch 4/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.4533 - accuracy: 0.8435 - val_loss: 0.6515 - val_accuracy: 0.7912\n",
            "Epoch 5/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.4448 - accuracy: 0.8440 - val_loss: 0.5613 - val_accuracy: 0.8104\n",
            "Epoch 6/30\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 0.4396 - accuracy: 0.8459 - val_loss: 0.6198 - val_accuracy: 0.8026\n",
            "Epoch 7/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.4383 - accuracy: 0.8471 - val_loss: 0.6001 - val_accuracy: 0.8074\n",
            "Epoch 8/30\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.4333 - accuracy: 0.8493 - val_loss: 0.5018 - val_accuracy: 0.8324\n",
            "Epoch 9/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.4297 - accuracy: 0.8501 - val_loss: 0.5326 - val_accuracy: 0.8265\n",
            "Epoch 10/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.4308 - accuracy: 0.8500 - val_loss: 0.5224 - val_accuracy: 0.8261\n",
            "Epoch 11/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.4247 - accuracy: 0.8527 - val_loss: 0.6710 - val_accuracy: 0.7927\n",
            "Epoch 12/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.4190 - accuracy: 0.8530 - val_loss: 0.5916 - val_accuracy: 0.8117\n",
            "Epoch 13/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.4165 - accuracy: 0.8556 - val_loss: 0.6275 - val_accuracy: 0.7996\n",
            "Epoch 14/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.4164 - accuracy: 0.8538 - val_loss: 0.6319 - val_accuracy: 0.7998\n",
            "Epoch 15/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.4116 - accuracy: 0.8563 - val_loss: 0.6627 - val_accuracy: 0.7924\n",
            "Epoch 16/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.4141 - accuracy: 0.8551 - val_loss: 0.5942 - val_accuracy: 0.8062\n",
            "Epoch 17/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.4093 - accuracy: 0.8582 - val_loss: 0.6255 - val_accuracy: 0.8014\n",
            "Epoch 18/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.4033 - accuracy: 0.8601 - val_loss: 0.5755 - val_accuracy: 0.8152\n",
            "Epoch 19/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.4066 - accuracy: 0.8584 - val_loss: 0.4705 - val_accuracy: 0.8411\n",
            "Epoch 20/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3985 - accuracy: 0.8588 - val_loss: 0.5003 - val_accuracy: 0.8320\n",
            "Epoch 21/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.3943 - accuracy: 0.8619 - val_loss: 0.4802 - val_accuracy: 0.8446\n",
            "Epoch 22/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.3953 - accuracy: 0.8623 - val_loss: 0.5594 - val_accuracy: 0.8188\n",
            "Epoch 23/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.3933 - accuracy: 0.8622 - val_loss: 0.5043 - val_accuracy: 0.8343\n",
            "Epoch 24/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3888 - accuracy: 0.8633 - val_loss: 0.5373 - val_accuracy: 0.8254\n",
            "Epoch 25/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.3857 - accuracy: 0.8644 - val_loss: 0.6445 - val_accuracy: 0.8035\n",
            "Epoch 26/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.3846 - accuracy: 0.8644 - val_loss: 0.4975 - val_accuracy: 0.8416\n",
            "Epoch 27/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3821 - accuracy: 0.8656 - val_loss: 0.4914 - val_accuracy: 0.8339\n",
            "Epoch 28/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3779 - accuracy: 0.8664 - val_loss: 0.4787 - val_accuracy: 0.8427\n",
            "Epoch 29/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3762 - accuracy: 0.8671 - val_loss: 0.5086 - val_accuracy: 0.8338\n",
            "Epoch 30/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3763 - accuracy: 0.8679 - val_loss: 0.4758 - val_accuracy: 0.8421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aUgF2wxQ_kiO",
        "outputId": "ae86ce2c-b1f6-4dbf-d45f-cb5b091e0ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 30, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_new_120epochs.h5'))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3709 - accuracy: 0.8698 - val_loss: 0.4988 - val_accuracy: 0.8364\n",
            "Epoch 2/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3689 - accuracy: 0.8708 - val_loss: 0.5581 - val_accuracy: 0.8205\n",
            "Epoch 3/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.3643 - accuracy: 0.8724 - val_loss: 0.5163 - val_accuracy: 0.8325\n",
            "Epoch 4/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3681 - accuracy: 0.8701 - val_loss: 0.5318 - val_accuracy: 0.8264\n",
            "Epoch 5/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3605 - accuracy: 0.8748 - val_loss: 0.5757 - val_accuracy: 0.8181\n",
            "Epoch 6/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3561 - accuracy: 0.8774 - val_loss: 0.5582 - val_accuracy: 0.8253\n",
            "Epoch 7/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3530 - accuracy: 0.8755 - val_loss: 0.4628 - val_accuracy: 0.8457\n",
            "Epoch 8/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.3521 - accuracy: 0.8769 - val_loss: 0.5477 - val_accuracy: 0.8254\n",
            "Epoch 9/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.3562 - accuracy: 0.8743 - val_loss: 0.4886 - val_accuracy: 0.8379\n",
            "Epoch 10/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3491 - accuracy: 0.8788 - val_loss: 0.6067 - val_accuracy: 0.8095\n",
            "Epoch 11/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.3467 - accuracy: 0.8788 - val_loss: 0.4536 - val_accuracy: 0.8481\n",
            "Epoch 12/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3466 - accuracy: 0.8790 - val_loss: 0.5083 - val_accuracy: 0.8370\n",
            "Epoch 13/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.3446 - accuracy: 0.8802 - val_loss: 0.4969 - val_accuracy: 0.8363\n",
            "Epoch 14/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.3453 - accuracy: 0.8790 - val_loss: 0.5665 - val_accuracy: 0.8253\n",
            "Epoch 15/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.3395 - accuracy: 0.8821 - val_loss: 0.5026 - val_accuracy: 0.8397\n",
            "Epoch 16/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.3389 - accuracy: 0.8804 - val_loss: 0.4352 - val_accuracy: 0.8544\n",
            "Epoch 17/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.3358 - accuracy: 0.8830 - val_loss: 0.4630 - val_accuracy: 0.8514\n",
            "Epoch 18/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.3362 - accuracy: 0.8814 - val_loss: 0.5628 - val_accuracy: 0.8256\n",
            "Epoch 19/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.3353 - accuracy: 0.8831 - val_loss: 0.5729 - val_accuracy: 0.8241\n",
            "Epoch 20/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.3313 - accuracy: 0.8854 - val_loss: 0.5225 - val_accuracy: 0.8360\n",
            "Epoch 21/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3308 - accuracy: 0.8825 - val_loss: 0.5445 - val_accuracy: 0.8297\n",
            "Epoch 22/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.3281 - accuracy: 0.8861 - val_loss: 0.5421 - val_accuracy: 0.8326\n",
            "Epoch 23/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.3261 - accuracy: 0.8868 - val_loss: 0.5369 - val_accuracy: 0.8306\n",
            "Epoch 24/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.3245 - accuracy: 0.8853 - val_loss: 0.5940 - val_accuracy: 0.8201\n",
            "Epoch 25/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3258 - accuracy: 0.8848 - val_loss: 0.4445 - val_accuracy: 0.8566\n",
            "Epoch 26/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.3189 - accuracy: 0.8874 - val_loss: 0.5087 - val_accuracy: 0.8384\n",
            "Epoch 27/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3208 - accuracy: 0.8883 - val_loss: 0.4585 - val_accuracy: 0.8496\n",
            "Epoch 28/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3174 - accuracy: 0.8893 - val_loss: 0.4624 - val_accuracy: 0.8530\n",
            "Epoch 29/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3175 - accuracy: 0.8899 - val_loss: 0.4626 - val_accuracy: 0.8519\n",
            "Epoch 30/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.3142 - accuracy: 0.8893 - val_loss: 0.4622 - val_accuracy: 0.8519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3DSvjo7j_4Co",
        "outputId": "3f948649-cdec-4f7c-ec2e-48aee03cbc47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 30, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_new_150epochs.h5'))\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3101 - accuracy: 0.8923 - val_loss: 0.4372 - val_accuracy: 0.8559\n",
            "Epoch 2/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.3104 - accuracy: 0.8897 - val_loss: 0.4566 - val_accuracy: 0.8507\n",
            "Epoch 3/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3067 - accuracy: 0.8931 - val_loss: 0.4852 - val_accuracy: 0.8471\n",
            "Epoch 4/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.3078 - accuracy: 0.8914 - val_loss: 0.5366 - val_accuracy: 0.8327\n",
            "Epoch 5/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.3023 - accuracy: 0.8954 - val_loss: 0.5466 - val_accuracy: 0.8345\n",
            "Epoch 6/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.3022 - accuracy: 0.8939 - val_loss: 0.5084 - val_accuracy: 0.8406\n",
            "Epoch 7/30\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.3026 - accuracy: 0.8930 - val_loss: 0.4417 - val_accuracy: 0.8548\n",
            "Epoch 8/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2980 - accuracy: 0.8948 - val_loss: 0.5283 - val_accuracy: 0.8350\n",
            "Epoch 9/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2988 - accuracy: 0.8951 - val_loss: 0.4844 - val_accuracy: 0.8471\n",
            "Epoch 10/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2996 - accuracy: 0.8951 - val_loss: 0.4265 - val_accuracy: 0.8644\n",
            "Epoch 11/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2982 - accuracy: 0.8953 - val_loss: 0.4392 - val_accuracy: 0.8598\n",
            "Epoch 12/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2961 - accuracy: 0.8961 - val_loss: 0.5158 - val_accuracy: 0.8366\n",
            "Epoch 13/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2906 - accuracy: 0.8976 - val_loss: 0.5237 - val_accuracy: 0.8404\n",
            "Epoch 14/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2877 - accuracy: 0.8993 - val_loss: 0.4760 - val_accuracy: 0.8540\n",
            "Epoch 15/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2878 - accuracy: 0.8988 - val_loss: 0.5600 - val_accuracy: 0.8267\n",
            "Epoch 16/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2901 - accuracy: 0.8973 - val_loss: 0.4110 - val_accuracy: 0.8660\n",
            "Epoch 17/30\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.2862 - accuracy: 0.9004 - val_loss: 0.4698 - val_accuracy: 0.8568\n",
            "Epoch 18/30\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.2834 - accuracy: 0.8990 - val_loss: 0.4755 - val_accuracy: 0.8545\n",
            "Epoch 19/30\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.2861 - accuracy: 0.9007 - val_loss: 0.5179 - val_accuracy: 0.8377\n",
            "Epoch 20/30\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.2845 - accuracy: 0.8997 - val_loss: 0.5602 - val_accuracy: 0.8319\n",
            "Epoch 21/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2776 - accuracy: 0.9037 - val_loss: 0.5171 - val_accuracy: 0.8415\n",
            "Epoch 22/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.2841 - accuracy: 0.9001 - val_loss: 0.4847 - val_accuracy: 0.8510\n",
            "Epoch 23/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2803 - accuracy: 0.9016 - val_loss: 0.4602 - val_accuracy: 0.8565\n",
            "Epoch 24/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2739 - accuracy: 0.9030 - val_loss: 0.5062 - val_accuracy: 0.8454\n",
            "Epoch 25/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.2740 - accuracy: 0.9025 - val_loss: 0.4562 - val_accuracy: 0.8573\n",
            "Epoch 26/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.2753 - accuracy: 0.9021 - val_loss: 0.4560 - val_accuracy: 0.8604\n",
            "Epoch 27/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.2757 - accuracy: 0.9038 - val_loss: 0.4813 - val_accuracy: 0.8495\n",
            "Epoch 28/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2731 - accuracy: 0.9042 - val_loss: 0.3907 - val_accuracy: 0.8738\n",
            "Epoch 29/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2697 - accuracy: 0.9049 - val_loss: 0.5149 - val_accuracy: 0.8468\n",
            "Epoch 30/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2719 - accuracy: 0.9057 - val_loss: 0.4990 - val_accuracy: 0.8483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R2_pqkpwlWxf",
        "outputId": "1685ff83-db1b-4eee-b65a-f6accca7c551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "path = os.path.abspath('gdrive/My Drive/CNN_CIFAR')\n",
        "path = os.path.join(path, 'Cifar_training')\n",
        "model = load_model('/content/gdrive/My Drive/CNN_CIFAR/Cifar_training/cnn_cifar_model_new1.hdf5')\n",
        "model.load_weights(os.path.join(path, 'model_new_150epochs.h5'))\n",
        "keras.backend.set_value(model.optimizer.lr, 0.001)\n",
        "checkpoint = ModelCheckpoint(os.path.join(path, 'cnn_cifar_model_new.hdf5'), monitor = 'val_acc')\n",
        "datagen = ImageDataGenerator(rotation_range = 15, horizontal_flip = True, width_shift_range = 0.1, height_shift_range = 0.1, zoom_range = 0.2, shear_range = 15)\n",
        "datagen.fit(X_train)\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 30, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_180epochs.h5'))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "391/390 [==============================] - 87s 223ms/step - loss: 0.2433 - accuracy: 0.9137 - val_loss: 0.3915 - val_accuracy: 0.8722\n",
            "Epoch 2/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2301 - accuracy: 0.9202 - val_loss: 0.3770 - val_accuracy: 0.8757\n",
            "Epoch 3/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2310 - accuracy: 0.9195 - val_loss: 0.3831 - val_accuracy: 0.8751\n",
            "Epoch 4/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2264 - accuracy: 0.9193 - val_loss: 0.3884 - val_accuracy: 0.8770\n",
            "Epoch 5/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2292 - accuracy: 0.9196 - val_loss: 0.3894 - val_accuracy: 0.8759\n",
            "Epoch 6/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2257 - accuracy: 0.9216 - val_loss: 0.3884 - val_accuracy: 0.8767\n",
            "Epoch 7/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2274 - accuracy: 0.9200 - val_loss: 0.3821 - val_accuracy: 0.8774\n",
            "Epoch 8/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.2246 - accuracy: 0.9211 - val_loss: 0.3999 - val_accuracy: 0.8717\n",
            "Epoch 9/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.2226 - accuracy: 0.9220 - val_loss: 0.4015 - val_accuracy: 0.8729\n",
            "Epoch 10/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2225 - accuracy: 0.9234 - val_loss: 0.3856 - val_accuracy: 0.8771\n",
            "Epoch 11/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2193 - accuracy: 0.9242 - val_loss: 0.4039 - val_accuracy: 0.8729\n",
            "Epoch 12/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2181 - accuracy: 0.9228 - val_loss: 0.3908 - val_accuracy: 0.8766\n",
            "Epoch 13/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2209 - accuracy: 0.9231 - val_loss: 0.3766 - val_accuracy: 0.8802\n",
            "Epoch 14/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2222 - accuracy: 0.9219 - val_loss: 0.3784 - val_accuracy: 0.8764\n",
            "Epoch 15/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2188 - accuracy: 0.9232 - val_loss: 0.3897 - val_accuracy: 0.8748\n",
            "Epoch 16/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2197 - accuracy: 0.9236 - val_loss: 0.3816 - val_accuracy: 0.8769\n",
            "Epoch 17/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2183 - accuracy: 0.9232 - val_loss: 0.3899 - val_accuracy: 0.8773\n",
            "Epoch 18/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2137 - accuracy: 0.9246 - val_loss: 0.3806 - val_accuracy: 0.8774\n",
            "Epoch 19/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2224 - accuracy: 0.9219 - val_loss: 0.3809 - val_accuracy: 0.8792\n",
            "Epoch 20/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.2178 - accuracy: 0.9229 - val_loss: 0.4025 - val_accuracy: 0.8729\n",
            "Epoch 21/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2169 - accuracy: 0.9246 - val_loss: 0.3906 - val_accuracy: 0.8766\n",
            "Epoch 22/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2160 - accuracy: 0.9238 - val_loss: 0.3914 - val_accuracy: 0.8773\n",
            "Epoch 23/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2172 - accuracy: 0.9230 - val_loss: 0.3859 - val_accuracy: 0.8775\n",
            "Epoch 24/30\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2104 - accuracy: 0.9263 - val_loss: 0.3916 - val_accuracy: 0.8781\n",
            "Epoch 25/30\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.2119 - accuracy: 0.9254 - val_loss: 0.3897 - val_accuracy: 0.8770\n",
            "Epoch 26/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2153 - accuracy: 0.9244 - val_loss: 0.3834 - val_accuracy: 0.8788\n",
            "Epoch 27/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2142 - accuracy: 0.9238 - val_loss: 0.3840 - val_accuracy: 0.8770\n",
            "Epoch 28/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2163 - accuracy: 0.9252 - val_loss: 0.3755 - val_accuracy: 0.8804\n",
            "Epoch 29/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2141 - accuracy: 0.9248 - val_loss: 0.3883 - val_accuracy: 0.8767\n",
            "Epoch 30/30\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2135 - accuracy: 0.9249 - val_loss: 0.3915 - val_accuracy: 0.8780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCqq61FK99C7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "4beb7555-2a07-4e85-8b01-0e09403f5e9d"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "path = os.path.abspath('gdrive/My Drive/CNN_CIFAR')\n",
        "path = os.path.join(path, 'Cifar_training')\n",
        "model = load_model('/content/gdrive/My Drive/CNN_CIFAR/Cifar_training/cnn_cifar_model_new1.hdf5')\n",
        "model.load_weights(os.path.join(path, 'model_180epochs.h5'))\n",
        "keras.backend.set_value(model.optimizer.lr, 0.0001)\n",
        "checkpoint = ModelCheckpoint(os.path.join(path, 'cnn_cifar_model_new1.hdf5'), monitor = 'val_acc')\n",
        "datagen = ImageDataGenerator(rotation_range = 15, horizontal_flip = True, width_shift_range = 0.1, height_shift_range = 0.1, zoom_range = 0.2, shear_range = 15)\n",
        "datagen.fit(X_train)\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 10, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_new_190epochs.h5'))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 0.2100 - accuracy: 0.9256 - val_loss: 0.3873 - val_accuracy: 0.8776\n",
            "Epoch 2/10\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2112 - accuracy: 0.9251 - val_loss: 0.3847 - val_accuracy: 0.8796\n",
            "Epoch 3/10\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2089 - accuracy: 0.9278 - val_loss: 0.3867 - val_accuracy: 0.8779\n",
            "Epoch 4/10\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.2105 - accuracy: 0.9249 - val_loss: 0.3844 - val_accuracy: 0.8788\n",
            "Epoch 5/10\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.2105 - accuracy: 0.9258 - val_loss: 0.3804 - val_accuracy: 0.8801\n",
            "Epoch 6/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2106 - accuracy: 0.9266 - val_loss: 0.3850 - val_accuracy: 0.8788\n",
            "Epoch 7/10\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2071 - accuracy: 0.9275 - val_loss: 0.3820 - val_accuracy: 0.8803\n",
            "Epoch 8/10\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2096 - accuracy: 0.9274 - val_loss: 0.3822 - val_accuracy: 0.8799\n",
            "Epoch 9/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2094 - accuracy: 0.9261 - val_loss: 0.3818 - val_accuracy: 0.8809\n",
            "Epoch 10/10\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2066 - accuracy: 0.9264 - val_loss: 0.3791 - val_accuracy: 0.8810\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0tlEJTqF0sE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "8ec98b75-096a-4f44-8e5e-6141e959a2d4"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "path = os.path.abspath('gdrive/My Drive/CNN_CIFAR')\n",
        "path = os.path.join(path, 'Cifar_training')\n",
        "model = load_model('/content/gdrive/My Drive/CNN_CIFAR/Cifar_training/cnn_cifar_model_new1.hdf5')\n",
        "model.load_weights(os.path.join(path, 'model_new_190epochs.h5'))\n",
        "keras.backend.set_value(model.optimizer.lr, 0.0001)\n",
        "checkpoint = ModelCheckpoint(os.path.join(path, 'cnn_cifar_model_new1.hdf5'), monitor = 'val_acc')\n",
        "datagen = ImageDataGenerator(rotation_range = 15, horizontal_flip = True, width_shift_range = 0.1, height_shift_range = 0.1, zoom_range = 0.2, shear_range = 15)\n",
        "datagen.fit(X_train)\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 10, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_new_200epochs.h5'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-03751f19b93e>:13: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/10\n",
            "391/390 [==============================] - 90s 231ms/step - loss: 0.2092 - accuracy: 0.9270 - val_loss: 0.3844 - val_accuracy: 0.8793\n",
            "Epoch 2/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2074 - accuracy: 0.9278 - val_loss: 0.3801 - val_accuracy: 0.8807\n",
            "Epoch 3/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2092 - accuracy: 0.9267 - val_loss: 0.3844 - val_accuracy: 0.8792\n",
            "Epoch 4/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2096 - accuracy: 0.9258 - val_loss: 0.3794 - val_accuracy: 0.8807\n",
            "Epoch 5/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2078 - accuracy: 0.9270 - val_loss: 0.3835 - val_accuracy: 0.8801\n",
            "Epoch 6/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2056 - accuracy: 0.9285 - val_loss: 0.3802 - val_accuracy: 0.8802\n",
            "Epoch 7/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2095 - accuracy: 0.9266 - val_loss: 0.3840 - val_accuracy: 0.8784\n",
            "Epoch 8/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2103 - accuracy: 0.9257 - val_loss: 0.3824 - val_accuracy: 0.8791\n",
            "Epoch 9/10\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.2110 - accuracy: 0.9261 - val_loss: 0.3829 - val_accuracy: 0.8789\n",
            "Epoch 10/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2077 - accuracy: 0.9267 - val_loss: 0.3820 - val_accuracy: 0.8784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j86DNWnHEDTD",
        "outputId": "db5a8943-064b-4880-c160-ec77c66564ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "path = os.path.abspath('gdrive/My Drive/CNN_CIFAR')\n",
        "path = os.path.join(path, 'Cifar_training')\n",
        "model = load_model('/content/gdrive/My Drive/CNN_CIFAR/Cifar_training/cnn_cifar_model_new1.hdf5')\n",
        "model.load_weights(os.path.join(path, 'model_new_200epochs.h5'))\n",
        "keras.backend.set_value(model.optimizer.lr, 0.00001)\n",
        "checkpoint = ModelCheckpoint(os.path.join(path, 'cnn_cifar_model_new1.hdf5'), monitor = 'val_acc')\n",
        "datagen = ImageDataGenerator(rotation_range = 15, horizontal_flip = True, width_shift_range = 0.1, height_shift_range = 0.1, zoom_range = 0.2, shear_range = 15)\n",
        "datagen.fit(X_train)\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 10, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_new_210epochs.h5'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2082 - accuracy: 0.9273 - val_loss: 0.3813 - val_accuracy: 0.8790\n",
            "Epoch 2/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2097 - accuracy: 0.9261 - val_loss: 0.3818 - val_accuracy: 0.8789\n",
            "Epoch 3/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2072 - accuracy: 0.9260 - val_loss: 0.3815 - val_accuracy: 0.8785\n",
            "Epoch 4/10\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.2084 - accuracy: 0.9264 - val_loss: 0.3845 - val_accuracy: 0.8778\n",
            "Epoch 5/10\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.2066 - accuracy: 0.9269 - val_loss: 0.3808 - val_accuracy: 0.8794\n",
            "Epoch 6/10\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.2057 - accuracy: 0.9274 - val_loss: 0.3812 - val_accuracy: 0.8794\n",
            "Epoch 7/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2081 - accuracy: 0.9272 - val_loss: 0.3805 - val_accuracy: 0.8794\n",
            "Epoch 8/10\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.2099 - accuracy: 0.9273 - val_loss: 0.3809 - val_accuracy: 0.8799\n",
            "Epoch 9/10\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.2097 - accuracy: 0.9259 - val_loss: 0.3816 - val_accuracy: 0.8793\n",
            "Epoch 10/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2095 - accuracy: 0.9261 - val_loss: 0.3824 - val_accuracy: 0.8789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zjLn28261OXe",
        "outputId": "2da761c3-ac26-4a47-f112-8cdedea33e1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "path = os.path.abspath('gdrive/My Drive/CNN_CIFAR')\n",
        "path = os.path.join(path, 'Cifar_training')\n",
        "model = load_model('/content/gdrive/My Drive/CNN_CIFAR/Cifar_training/cnn_cifar_model_new1.hdf5')\n",
        "model.load_weights(os.path.join(path, 'model_new_210epochs.h5'))\n",
        "keras.backend.set_value(model.optimizer.lr, 0.000001)\n",
        "checkpoint = ModelCheckpoint(os.path.join(path, 'cnn_cifar_model_new1.hdf5'), monitor = 'val_acc')\n",
        "datagen = ImageDataGenerator(rotation_range = 15, horizontal_flip = True, width_shift_range = 0.1, height_shift_range = 0.1, zoom_range = 0.2, shear_range = 15)\n",
        "datagen.fit(X_train)\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 10, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_new_220epochs.h5'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.2068 - accuracy: 0.9271 - val_loss: 0.3794 - val_accuracy: 0.8804\n",
            "Epoch 2/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2090 - accuracy: 0.9275 - val_loss: 0.3814 - val_accuracy: 0.8790\n",
            "Epoch 3/10\n",
            "391/390 [==============================] - 86s 219ms/step - loss: 0.2078 - accuracy: 0.9266 - val_loss: 0.3826 - val_accuracy: 0.8792\n",
            "Epoch 4/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2065 - accuracy: 0.9278 - val_loss: 0.3835 - val_accuracy: 0.8788\n",
            "Epoch 5/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2078 - accuracy: 0.9262 - val_loss: 0.3826 - val_accuracy: 0.8790\n",
            "Epoch 6/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2086 - accuracy: 0.9270 - val_loss: 0.3830 - val_accuracy: 0.8792\n",
            "Epoch 7/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2079 - accuracy: 0.9275 - val_loss: 0.3825 - val_accuracy: 0.8792\n",
            "Epoch 8/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2091 - accuracy: 0.9262 - val_loss: 0.3839 - val_accuracy: 0.8786\n",
            "Epoch 9/10\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 0.2077 - accuracy: 0.9271 - val_loss: 0.3822 - val_accuracy: 0.8786\n",
            "Epoch 10/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2117 - accuracy: 0.9254 - val_loss: 0.3831 - val_accuracy: 0.8788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k8OqdDgUsVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "1b32c740-54ac-414b-ec3a-61001ed05b06"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "path = os.path.abspath('gdrive/My Drive/CNN_CIFAR')\n",
        "path = os.path.join(path, 'Cifar_training')\n",
        "model = load_model('/content/gdrive/My Drive/CNN_CIFAR/Cifar_training/cnn_cifar_model_new1.hdf5')\n",
        "model.load_weights(os.path.join(path, 'model_new_220epochs.h5'))\n",
        "keras.backend.set_value(model.optimizer.lr, 0.0000001)\n",
        "checkpoint = ModelCheckpoint(os.path.join(path, 'cnn_cifar_model_new1.hdf5'), monitor = 'val_acc')\n",
        "datagen = ImageDataGenerator(rotation_range = 15, horizontal_flip = True, width_shift_range = 0.1, height_shift_range = 0.1, zoom_range = 0.2, shear_range = 15)\n",
        "datagen.fit(X_train)\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 10, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_new_230epochs.h5'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 0.2070 - accuracy: 0.9283 - val_loss: 0.3819 - val_accuracy: 0.8791\n",
            "Epoch 2/10\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.2054 - accuracy: 0.9287 - val_loss: 0.3818 - val_accuracy: 0.8792\n",
            "Epoch 3/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2074 - accuracy: 0.9272 - val_loss: 0.3823 - val_accuracy: 0.8792\n",
            "Epoch 4/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2072 - accuracy: 0.9265 - val_loss: 0.3814 - val_accuracy: 0.8795\n",
            "Epoch 5/10\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.2095 - accuracy: 0.9271 - val_loss: 0.3829 - val_accuracy: 0.8786\n",
            "Epoch 6/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2079 - accuracy: 0.9281 - val_loss: 0.3823 - val_accuracy: 0.8789\n",
            "Epoch 7/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2085 - accuracy: 0.9272 - val_loss: 0.3807 - val_accuracy: 0.8799\n",
            "Epoch 8/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2083 - accuracy: 0.9257 - val_loss: 0.3820 - val_accuracy: 0.8792\n",
            "Epoch 9/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2116 - accuracy: 0.9263 - val_loss: 0.3815 - val_accuracy: 0.8792\n",
            "Epoch 10/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2061 - accuracy: 0.9275 - val_loss: 0.3823 - val_accuracy: 0.8788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CTPCKLGeMp1L",
        "outputId": "e0c489ba-563d-4c08-a1dc-04b0a88477ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "path = os.path.abspath('gdrive/My Drive/CNN_CIFAR')\n",
        "path = os.path.join(path, 'Cifar_training')\n",
        "model = load_model('/content/gdrive/My Drive/CNN_CIFAR/Cifar_training/cnn_cifar_model_new1.hdf5')\n",
        "model.load_weights(os.path.join(path, 'model_new_230epochs.h5'))\n",
        "keras.backend.set_value(model.optimizer.lr, 0.001)\n",
        "checkpoint = ModelCheckpoint(os.path.join(path, 'cnn_cifar_model_new1.hdf5'), monitor = 'val_acc')\n",
        "datagen = ImageDataGenerator(rotation_range = 15, horizontal_flip = True, width_shift_range = 0.1, height_shift_range = 0.1, zoom_range = 0.2, shear_range = 15)\n",
        "datagen.fit(X_train)\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 10, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_new_240epochs.h5'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 0.2113 - accuracy: 0.9245 - val_loss: 0.3870 - val_accuracy: 0.8771\n",
            "Epoch 2/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2130 - accuracy: 0.9260 - val_loss: 0.4107 - val_accuracy: 0.8719\n",
            "Epoch 3/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2150 - accuracy: 0.9246 - val_loss: 0.3936 - val_accuracy: 0.8766\n",
            "Epoch 4/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2128 - accuracy: 0.9247 - val_loss: 0.3988 - val_accuracy: 0.8765\n",
            "Epoch 5/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2096 - accuracy: 0.9269 - val_loss: 0.3807 - val_accuracy: 0.8807\n",
            "Epoch 6/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2110 - accuracy: 0.9252 - val_loss: 0.3818 - val_accuracy: 0.8801\n",
            "Epoch 7/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2118 - accuracy: 0.9261 - val_loss: 0.3922 - val_accuracy: 0.8785\n",
            "Epoch 8/10\n",
            "391/390 [==============================] - 85s 219ms/step - loss: 0.2134 - accuracy: 0.9242 - val_loss: 0.3694 - val_accuracy: 0.8831\n",
            "Epoch 9/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2099 - accuracy: 0.9258 - val_loss: 0.3919 - val_accuracy: 0.8776\n",
            "Epoch 10/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.2096 - accuracy: 0.9257 - val_loss: 0.3782 - val_accuracy: 0.8804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vwfauGUtQEwC",
        "outputId": "1ec03675-5f55-4154-e32b-14ab624b794a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "path = os.path.abspath('gdrive/My Drive/CNN_CIFAR')\n",
        "path = os.path.join(path, 'Cifar_training')\n",
        "model = load_model('/content/gdrive/My Drive/CNN_CIFAR/Cifar_training/cnn_cifar_model_new1.hdf5')\n",
        "model.load_weights(os.path.join(path, 'model_new_240epochs.h5'))\n",
        "keras.backend.set_value(model.optimizer.lr, 0.001)\n",
        "checkpoint = ModelCheckpoint(os.path.join(path, 'cnn_cifar_model_new1.hdf5'), monitor = 'val_acc')\n",
        "datagen = ImageDataGenerator(rotation_range = 15, horizontal_flip = True, width_shift_range = 0.1, height_shift_range = 0.1)\n",
        "datagen.fit(X_train)\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 10, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_new_250epochs.h5'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/390 [==============================] - 86s 220ms/step - loss: 0.1612 - accuracy: 0.9447 - val_loss: 0.3827 - val_accuracy: 0.8804\n",
            "Epoch 2/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1590 - accuracy: 0.9449 - val_loss: 0.3883 - val_accuracy: 0.8795\n",
            "Epoch 3/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1569 - accuracy: 0.9460 - val_loss: 0.3925 - val_accuracy: 0.8780\n",
            "Epoch 4/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1566 - accuracy: 0.9457 - val_loss: 0.3749 - val_accuracy: 0.8807\n",
            "Epoch 5/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1561 - accuracy: 0.9455 - val_loss: 0.3712 - val_accuracy: 0.8816\n",
            "Epoch 6/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1573 - accuracy: 0.9449 - val_loss: 0.3715 - val_accuracy: 0.8849\n",
            "Epoch 7/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1581 - accuracy: 0.9456 - val_loss: 0.3800 - val_accuracy: 0.8820\n",
            "Epoch 8/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1588 - accuracy: 0.9450 - val_loss: 0.3781 - val_accuracy: 0.8819\n",
            "Epoch 9/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1545 - accuracy: 0.9466 - val_loss: 0.3744 - val_accuracy: 0.8832\n",
            "Epoch 10/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1563 - accuracy: 0.9457 - val_loss: 0.3868 - val_accuracy: 0.8814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D0zrWY89TMLl",
        "outputId": "0cf52bc5-1e7f-4a63-c7c2-e228b61eddc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 10, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_260epochs.h5'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1524 - accuracy: 0.9469 - val_loss: 0.3701 - val_accuracy: 0.8845\n",
            "Epoch 2/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1543 - accuracy: 0.9462 - val_loss: 0.3691 - val_accuracy: 0.8848\n",
            "Epoch 3/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1536 - accuracy: 0.9461 - val_loss: 0.3690 - val_accuracy: 0.8859\n",
            "Epoch 4/10\n",
            "391/390 [==============================] - 85s 217ms/step - loss: 0.1521 - accuracy: 0.9464 - val_loss: 0.3850 - val_accuracy: 0.8815\n",
            "Epoch 5/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1531 - accuracy: 0.9476 - val_loss: 0.3802 - val_accuracy: 0.8843\n",
            "Epoch 6/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1508 - accuracy: 0.9469 - val_loss: 0.3827 - val_accuracy: 0.8834\n",
            "Epoch 7/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1515 - accuracy: 0.9465 - val_loss: 0.3807 - val_accuracy: 0.8819\n",
            "Epoch 8/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1526 - accuracy: 0.9466 - val_loss: 0.3919 - val_accuracy: 0.8818\n",
            "Epoch 9/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1509 - accuracy: 0.9462 - val_loss: 0.3916 - val_accuracy: 0.8820\n",
            "Epoch 10/10\n",
            "391/390 [==============================] - 85s 218ms/step - loss: 0.1497 - accuracy: 0.9482 - val_loss: 0.3830 - val_accuracy: 0.8816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjzuXQlhTXpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "d5f0105c-f7b5-4176-f571-38f032931f82"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "path = os.path.abspath('gdrive/My Drive/CNN_CIFAR')\n",
        "path = os.path.join(path, 'Cifar_training')\n",
        "model = load_model('/content/gdrive/My Drive/CNN_CIFAR/Cifar_training/cnn_cifar_model_new1.hdf5')\n",
        "model.load_weights(os.path.join(path, 'model_260epochs.h5'))\n",
        "keras.backend.set_value(model.optimizer.lr, 0.001)\n",
        "checkpoint = ModelCheckpoint(os.path.join(path, 'cnn_cifar_model_new1.hdf5'), monitor = 'val_acc')\n",
        "datagen = ImageDataGenerator(rotation_range = 15, horizontal_flip = True, width_shift_range = 0.1, height_shift_range = 0.1)\n",
        "datagen.fit(X_train)\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 10, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_new_270epochs.h5'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-19c5a1d32407>:13: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/10\n",
            "391/390 [==============================] - 50s 128ms/step - loss: 0.1541 - accuracy: 0.9451 - val_loss: 0.3879 - val_accuracy: 0.8819\n",
            "Epoch 2/10\n",
            "391/390 [==============================] - 48s 123ms/step - loss: 0.1509 - accuracy: 0.9480 - val_loss: 0.3815 - val_accuracy: 0.8842\n",
            "Epoch 3/10\n",
            "391/390 [==============================] - 48s 123ms/step - loss: 0.1506 - accuracy: 0.9481 - val_loss: 0.3821 - val_accuracy: 0.8831\n",
            "Epoch 4/10\n",
            "391/390 [==============================] - 48s 123ms/step - loss: 0.1508 - accuracy: 0.9472 - val_loss: 0.3806 - val_accuracy: 0.8836\n",
            "Epoch 5/10\n",
            "391/390 [==============================] - 48s 123ms/step - loss: 0.1486 - accuracy: 0.9480 - val_loss: 0.3823 - val_accuracy: 0.8814\n",
            "Epoch 6/10\n",
            "391/390 [==============================] - 48s 123ms/step - loss: 0.1492 - accuracy: 0.9473 - val_loss: 0.3940 - val_accuracy: 0.8799\n",
            "Epoch 7/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1506 - accuracy: 0.9474 - val_loss: 0.3785 - val_accuracy: 0.8837\n",
            "Epoch 8/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1495 - accuracy: 0.9476 - val_loss: 0.3898 - val_accuracy: 0.8812\n",
            "Epoch 9/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1498 - accuracy: 0.9478 - val_loss: 0.3766 - val_accuracy: 0.8850\n",
            "Epoch 10/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1477 - accuracy: 0.9478 - val_loss: 0.3859 - val_accuracy: 0.8806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wh6fp1JWDvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "6f965055-890c-4666-dbce-1b4ad8b743dc"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "path = os.path.abspath('gdrive/My Drive/CNN_CIFAR')\n",
        "path = os.path.join(path, 'Cifar_training')\n",
        "model = load_model('/content/gdrive/My Drive/CNN_CIFAR/Cifar_training/cnn_cifar_model_new1.hdf5')\n",
        "model.load_weights(os.path.join(path, 'model_new_270epochs.h5'))\n",
        "keras.backend.set_value(model.optimizer.lr, 0.001)\n",
        "checkpoint = ModelCheckpoint(os.path.join(path, 'cnn_cifar_model_new1.hdf5'), monitor = 'val_acc')\n",
        "datagen = ImageDataGenerator(rotation_range = 15, horizontal_flip = True, width_shift_range = 0.1)\n",
        "datagen.fit(X_train)\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 10, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_new_280epochs.h5'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/390 [==============================] - 49s 124ms/step - loss: 0.1349 - accuracy: 0.9532 - val_loss: 0.3741 - val_accuracy: 0.8838\n",
            "Epoch 2/10\n",
            "391/390 [==============================] - 48s 123ms/step - loss: 0.1328 - accuracy: 0.9543 - val_loss: 0.3691 - val_accuracy: 0.8856\n",
            "Epoch 3/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1323 - accuracy: 0.9548 - val_loss: 0.3743 - val_accuracy: 0.8845\n",
            "Epoch 4/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1279 - accuracy: 0.9560 - val_loss: 0.3715 - val_accuracy: 0.8852\n",
            "Epoch 5/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1316 - accuracy: 0.9532 - val_loss: 0.3816 - val_accuracy: 0.8836\n",
            "Epoch 6/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1316 - accuracy: 0.9539 - val_loss: 0.3820 - val_accuracy: 0.8848\n",
            "Epoch 7/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1308 - accuracy: 0.9542 - val_loss: 0.3811 - val_accuracy: 0.8849\n",
            "Epoch 8/10\n",
            "391/390 [==============================] - 49s 125ms/step - loss: 0.1291 - accuracy: 0.9554 - val_loss: 0.3827 - val_accuracy: 0.8859\n",
            "Epoch 9/10\n",
            "391/390 [==============================] - 49s 125ms/step - loss: 0.1306 - accuracy: 0.9546 - val_loss: 0.3694 - val_accuracy: 0.8854\n",
            "Epoch 10/10\n",
            "391/390 [==============================] - 48s 123ms/step - loss: 0.1285 - accuracy: 0.9552 - val_loss: 0.3859 - val_accuracy: 0.8842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTM_NwFnYYEd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "47d5d11b-229d-4546-ec30-4d2509a9e672"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "path = os.path.abspath('gdrive/My Drive/CNN_CIFAR')\n",
        "path = os.path.join(path, 'Cifar_training')\n",
        "model = load_model('/content/gdrive/My Drive/CNN_CIFAR/Cifar_training/cnn_cifar_model_new1.hdf5')\n",
        "model.load_weights(os.path.join(path, 'model_new_280epochs.h5'))\n",
        "keras.backend.set_value(model.optimizer.lr, 0.001)\n",
        "checkpoint = ModelCheckpoint(os.path.join(path, 'cnn_cifar_model_new1.hdf5'), monitor = 'val_acc')\n",
        "datagen = ImageDataGenerator(rotation_range = 15, horizontal_flip = True)\n",
        "datagen.fit(X_train)\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 10, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_new_290epochs.h5'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/390 [==============================] - 49s 124ms/step - loss: 0.1197 - accuracy: 0.9582 - val_loss: 0.3701 - val_accuracy: 0.8882\n",
            "Epoch 2/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1195 - accuracy: 0.9582 - val_loss: 0.3649 - val_accuracy: 0.8866\n",
            "Epoch 3/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1196 - accuracy: 0.9577 - val_loss: 0.3754 - val_accuracy: 0.8863\n",
            "Epoch 4/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1162 - accuracy: 0.9602 - val_loss: 0.3650 - val_accuracy: 0.8889\n",
            "Epoch 5/10\n",
            "391/390 [==============================] - 49s 124ms/step - loss: 0.1178 - accuracy: 0.9601 - val_loss: 0.3635 - val_accuracy: 0.8904\n",
            "Epoch 6/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1125 - accuracy: 0.9615 - val_loss: 0.3636 - val_accuracy: 0.8883\n",
            "Epoch 7/10\n",
            "391/390 [==============================] - 49s 124ms/step - loss: 0.1140 - accuracy: 0.9605 - val_loss: 0.3668 - val_accuracy: 0.8876\n",
            "Epoch 8/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1166 - accuracy: 0.9605 - val_loss: 0.3595 - val_accuracy: 0.8881\n",
            "Epoch 9/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1146 - accuracy: 0.9612 - val_loss: 0.3802 - val_accuracy: 0.8858\n",
            "Epoch 10/10\n",
            "391/390 [==============================] - 49s 124ms/step - loss: 0.1117 - accuracy: 0.9627 - val_loss: 0.3603 - val_accuracy: 0.8890\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkDKFHcab1EV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "714d3066-d710-4c2b-d64f-c6c748c3a6b6"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "path = os.path.abspath('gdrive/My Drive/CNN_CIFAR')\n",
        "path = os.path.join(path, 'Cifar_training')\n",
        "model = load_model('/content/gdrive/My Drive/CNN_CIFAR/Cifar_training/cnn_cifar_model_new1.hdf5')\n",
        "model.load_weights(os.path.join(path, 'model_new_290epochs.h5'))\n",
        "keras.backend.set_value(model.optimizer.lr, 0.0001)\n",
        "checkpoint = ModelCheckpoint(os.path.join(path, 'cnn_cifar_model_new1.hdf5'), monitor = 'val_acc')\n",
        "datagen = ImageDataGenerator(rotation_range = 15)\n",
        "datagen.fit(X_train)\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size), steps_per_epoch = X_train.shape[0]/batch_size, epochs = 10, validation_data =(X_test, y_test), callbacks = [checkpoint])\n",
        "model.save_weights(os.path.join(path, 'model_new_300epochs.h5'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/390 [==============================] - 49s 125ms/step - loss: 0.1119 - accuracy: 0.9613 - val_loss: 0.3632 - val_accuracy: 0.8881\n",
            "Epoch 2/10\n",
            "391/390 [==============================] - 49s 126ms/step - loss: 0.1093 - accuracy: 0.9629 - val_loss: 0.3631 - val_accuracy: 0.8886\n",
            "Epoch 3/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1092 - accuracy: 0.9618 - val_loss: 0.3632 - val_accuracy: 0.8890\n",
            "Epoch 4/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1093 - accuracy: 0.9621 - val_loss: 0.3627 - val_accuracy: 0.8889\n",
            "Epoch 5/10\n",
            "391/390 [==============================] - 49s 124ms/step - loss: 0.1102 - accuracy: 0.9622 - val_loss: 0.3644 - val_accuracy: 0.8886\n",
            "Epoch 6/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1085 - accuracy: 0.9629 - val_loss: 0.3625 - val_accuracy: 0.8892\n",
            "Epoch 7/10\n",
            "391/390 [==============================] - 49s 125ms/step - loss: 0.1077 - accuracy: 0.9626 - val_loss: 0.3634 - val_accuracy: 0.8883\n",
            "Epoch 8/10\n",
            "391/390 [==============================] - 49s 124ms/step - loss: 0.1083 - accuracy: 0.9621 - val_loss: 0.3630 - val_accuracy: 0.8885\n",
            "Epoch 9/10\n",
            "391/390 [==============================] - 49s 124ms/step - loss: 0.1084 - accuracy: 0.9627 - val_loss: 0.3617 - val_accuracy: 0.8892\n",
            "Epoch 10/10\n",
            "391/390 [==============================] - 48s 124ms/step - loss: 0.1059 - accuracy: 0.9628 - val_loss: 0.3620 - val_accuracy: 0.8894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DpM0aclbEmCu",
        "outputId": "5953ab06-34cf-4c37-f9f7-240544270812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/gdrive/My Drive/CNN_CIFAR/Cifar_training/cnn_cifar_model_new1.hdf5')\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3620 - accuracy: 0.8894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3620176315307617, 0.8894000053405762]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}